{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.0817</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.1168</td>\n",
       "      <td>0.1476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>0.1054</td>\n",
       "      <td>0.1109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0773</td>\n",
       "      <td>0.0862</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.1665</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.1443</td>\n",
       "      <td>0.2770</td>\n",
       "      <td>0.2555</td>\n",
       "      <td>0.1712</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "168  0.0015  0.0186  0.0289  0.0195  0.0515  0.0817  0.1005  0.0124  0.1168   \n",
       "70   0.0065  0.0122  0.0068  0.0108  0.0217  0.0284  0.0527  0.0575  0.1054   \n",
       "162  0.0217  0.0152  0.0346  0.0346  0.0484  0.0526  0.0773  0.0862  0.1451   \n",
       "79   0.0108  0.0086  0.0058  0.0460  0.0752  0.0887  0.1015  0.0494  0.0472   \n",
       "138  0.0731  0.1249  0.1665  0.1496  0.1443  0.2770  0.2555  0.1712  0.0466   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "168  0.1476  ...  0.0108  0.0075  0.0089  0.0036  0.0029  0.0013  0.0010   \n",
       "70   0.1109  ...  0.0069  0.0025  0.0027  0.0052  0.0036  0.0026  0.0036   \n",
       "162  0.2110  ...  0.0123  0.0067  0.0011  0.0026  0.0049  0.0029  0.0022   \n",
       "79   0.0393  ...  0.0029  0.0078  0.0114  0.0083  0.0058  0.0003  0.0023   \n",
       "138  0.1114  ...  0.0444  0.0230  0.0290  0.0141  0.0161  0.0177  0.0194   \n",
       "\n",
       "         58      59  60  \n",
       "168  0.0032  0.0047   M  \n",
       "70   0.0006  0.0035   R  \n",
       "162  0.0022  0.0032   M  \n",
       "79   0.0026  0.0027   R  \n",
       "138  0.0207  0.0057   M  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"data/sonar_dataset.csv\", header=None)\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "     ..\n",
       "56    0\n",
       "57    0\n",
       "58    0\n",
       "59    0\n",
       "60    0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "       54, 55, 56, 57, 58, 59, 60],\n",
       "      dtype='int64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60\n",
       "M    111\n",
       "R     97\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    R\n",
       "1    R\n",
       "2    R\n",
       "3    R\n",
       "4    R\n",
       "Name: 60, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= df.drop(60, axis=1)\n",
    "y= df[60]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         R\n",
       "0     True\n",
       "1     True\n",
       "2     True\n",
       "3     True\n",
       "4     True\n",
       "..     ...\n",
       "203  False\n",
       "204  False\n",
       "205  False\n",
       "206  False\n",
       "207  False\n",
       "\n",
       "[208 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y, drop_first=True)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156, 60), (52, 60))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "\tkeras.layers.Input(shape=(X_train.shape[1],)),\n",
    "\tkeras.layers.Dense(60, activation='relu'),\n",
    "\tkeras.layers.Dense(30, activation='relu'),\n",
    "\tkeras.layers.Dense(15, activation='relu'),\n",
    "\tkeras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4642 - loss: 0.6974\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.6055 - loss: 0.6549\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.6581 - loss: 0.6508\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.6687 - loss: 0.6292\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.7508 - loss: 0.5915\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.7431 - loss: 0.5775\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.7978 - loss: 0.5525\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.8634 - loss: 0.4688\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.7905 - loss: 0.4889\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8355 - loss: 0.4554 \n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7859 - loss: 0.4326 \n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.8784 - loss: 0.3642\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 0.8497 - loss: 0.3985\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.8731 - loss: 0.3812\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.8697 - loss: 0.3802\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.9344 - loss: 0.3074\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.8162 - loss: 0.3595\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.8394 - loss: 0.3711\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.8810 - loss: 0.2890\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9296 - loss: 0.2517\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.8751 - loss: 0.2773\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.9045 - loss: 0.2724\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9206 - loss: 0.2370 \n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.9225 - loss: 0.2393\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.8839 - loss: 0.2563\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.9346 - loss: 0.2032\n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9480 - loss: 0.1978 \n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.8991 - loss: 0.2391\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.9331 - loss: 0.1750\n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.9182 - loss: 0.1915\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.9469 - loss: 0.1719\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.9427 - loss: 0.1606\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 0.9718 - loss: 0.1544\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.9395 - loss: 0.1930\n",
      "Epoch 35/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.9407 - loss: 0.1723\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.9791 - loss: 0.1058\n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.9672 - loss: 0.1242\n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9542 - loss: 0.1317 \n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.9780 - loss: 0.0878\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.9444 - loss: 0.1517\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.9886 - loss: 0.0933\n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.9682 - loss: 0.1080\n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.9767 - loss: 0.1122\n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.9566 - loss: 0.1067\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.9936 - loss: 0.0733\n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.9883 - loss: 0.0884\n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9742 - loss: 0.0819\n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.9980 - loss: 0.0737\n",
      "Epoch 49/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.9987 - loss: 0.0514\n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.9937 - loss: 0.0599\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0559 \n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.9842 - loss: 0.0538\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 1.0000 - loss: 0.0366\n",
      "Epoch 54/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 1.0000 - loss: 0.0336\n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.9929 - loss: 0.0438\n",
      "Epoch 56/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.9783 - loss: 0.0469\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 1.0000 - loss: 0.0255\n",
      "Epoch 58/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.9976 - loss: 0.0447\n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9839 - loss: 0.0590 \n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0277 \n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0262 \n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 0.0238\n",
      "Epoch 63/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 1.0000 - loss: 0.0202\n",
      "Epoch 64/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 1.0000 - loss: 0.0261\n",
      "Epoch 65/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0186 \n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 1.0000 - loss: 0.0139\n",
      "Epoch 67/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 1.0000 - loss: 0.0152\n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 1.0000 - loss: 0.0134\n",
      "Epoch 69/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 1.0000 - loss: 0.0234\n",
      "Epoch 70/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0157 \n",
      "Epoch 71/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0147 \n",
      "Epoch 72/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 1.0000 - loss: 0.0164\n",
      "Epoch 73/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 0.0131\n",
      "Epoch 74/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0131 \n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0071     \n",
      "Epoch 76/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0102 \n",
      "Epoch 77/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 1.0000 - loss: 0.0103   \n",
      "Epoch 78/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 0.0111\n",
      "Epoch 79/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 1.0000 - loss: 0.0106\n",
      "Epoch 80/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 1.0000 - loss: 0.0102\n",
      "Epoch 81/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0093 \n",
      "Epoch 82/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 1.0000 - loss: 0.0080\n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 1.0000 - loss: 0.0073\n",
      "Epoch 84/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 1.0000 - loss: 0.0053\n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 86/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 1.0000 - loss: 0.0059\n",
      "Epoch 87/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0061 \n",
      "Epoch 88/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0061 \n",
      "Epoch 89/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0051 \n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 0.0069\n",
      "Epoch 91/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 1.0000 - loss: 0.0039   \n",
      "Epoch 92/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0057 \n",
      "Epoch 93/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 1.0000 - loss: 0.0046\n",
      "Epoch 94/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 1.0000 - loss: 0.0036\n",
      "Epoch 95/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 1.0000 - loss: 0.0039\n",
      "Epoch 96/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0032 \n",
      "Epoch 97/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0044 \n",
      "Epoch 98/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 1.0000 - loss: 0.0041\n",
      "Epoch 99/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 1.0000 - loss: 0.0040\n",
      "Epoch 100/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 1.0000 - loss: 0.0027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c7d45687a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9046 - loss: 0.2301  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23838336765766144, 0.9038461446762085]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
       "       0.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(X_test).reshape(-1).round()\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         R\n",
       "161  False\n",
       "15    True\n",
       "73    True\n",
       "96    True\n",
       "166  False\n",
       "9     True\n",
       "100  False\n",
       "135  False\n",
       "18    True\n",
       "148  False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_mtx = tf.math.confusion_matrix(labels=y_test, predictions=y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(33.22222222222222, 0.5, 'Truth')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "sns.heatmap(cnf_mtx, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.87      0.91        30\n",
      "        True       0.84      0.95      0.89        22\n",
      "\n",
      "    accuracy                           0.90        52\n",
      "   macro avg       0.90      0.91      0.90        52\n",
      "weighted avg       0.91      0.90      0.90        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential([\n",
    "\tkeras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "\tkeras.layers.Dense(60, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "\tkeras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "\tkeras.layers.Dense(15, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "\tkeras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model2.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4922 - loss: 0.8047\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4580 - loss: 0.7559 \n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5233 - loss: 0.7234 \n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4667 - loss: 0.7387 \n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4470 - loss: 0.7510 \n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5730 - loss: 0.7134 \n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5144 - loss: 0.7511 \n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5201 - loss: 0.6843 \n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5140 - loss: 0.7058 \n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5109 - loss: 0.6899 \n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4432 - loss: 0.7112 \n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4911 - loss: 0.7126 \n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4327 - loss: 0.7507 \n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5116 - loss: 0.7180 \n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5604 - loss: 0.6732 \n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4800 - loss: 0.7118 \n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5397 - loss: 0.6920 \n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5055 - loss: 0.7207 \n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3522 - loss: 0.7372 \n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.5546 - loss: 0.6909\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.4732 - loss: 0.7364\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.4971 - loss: 0.7119\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4909 - loss: 0.7093 \n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5196 - loss: 0.6913 \n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - accuracy: 0.5441 - loss: 0.6942\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4770 - loss: 0.6938 \n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5280 - loss: 0.6851 \n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 0.5255 - loss: 0.7116\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6157 - loss: 0.6707 \n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5567 - loss: 0.6832 \n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5061 - loss: 0.6995 \n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.6204 - loss: 0.6699\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5392 - loss: 0.6931 \n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4680 - loss: 0.7133 \n",
      "Epoch 35/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4986 - loss: 0.7116 \n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4979 - loss: 0.6795 \n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5494 - loss: 0.6876 \n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5266 - loss: 0.6898 \n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.6411 - loss: 0.6523\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4887 - loss: 0.6935 \n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5824 - loss: 0.6924 \n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5543 - loss: 0.6763 \n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5113 - loss: 0.6742 \n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5485 - loss: 0.6878 \n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5244 - loss: 0.7100 \n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4506 - loss: 0.6919 \n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4653 - loss: 0.6910 \n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.5718 - loss: 0.6853\n",
      "Epoch 49/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.6018 - loss: 0.6634\n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5443 - loss: 0.7118 \n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5666 - loss: 0.6555 \n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.6158 - loss: 0.6731\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5691 - loss: 0.6964 \n",
      "Epoch 54/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6505 - loss: 0.6424 \n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5984 - loss: 0.6665 \n",
      "Epoch 56/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5308 - loss: 0.6663 \n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5346 - loss: 0.6892 \n",
      "Epoch 58/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5864 - loss: 0.6606 \n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5779 - loss: 0.6960 \n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5466 - loss: 0.6865 \n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5625 - loss: 0.6976 \n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5855 - loss: 0.6849 \n",
      "Epoch 63/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5215 - loss: 0.6693 \n",
      "Epoch 64/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.5778 - loss: 0.6576\n",
      "Epoch 65/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.5282 - loss: 0.7018\n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.4902 - loss: 0.6961\n",
      "Epoch 67/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5066 - loss: 0.6855 \n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.4832 - loss: 0.7168\n",
      "Epoch 69/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.6002 - loss: 0.6746\n",
      "Epoch 70/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.5424 - loss: 0.6748\n",
      "Epoch 71/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.6020 - loss: 0.6782\n",
      "Epoch 72/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.6522 - loss: 0.6542\n",
      "Epoch 73/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.7047 - loss: 0.6303\n",
      "Epoch 74/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.5584 - loss: 0.6688\n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.6322 - loss: 0.6964\n",
      "Epoch 76/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.5671 - loss: 0.6633\n",
      "Epoch 77/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.5755 - loss: 0.6881\n",
      "Epoch 78/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.6338 - loss: 0.6630\n",
      "Epoch 79/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.5326 - loss: 0.6684\n",
      "Epoch 80/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.6333 - loss: 0.6462\n",
      "Epoch 81/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5390 - loss: 0.6568 \n",
      "Epoch 82/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.5163 - loss: 0.6952\n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.5459 - loss: 0.7157\n",
      "Epoch 84/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.6438 - loss: 0.6635\n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.6604 - loss: 0.6495\n",
      "Epoch 86/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5140 - loss: 0.6785 \n",
      "Epoch 87/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.5607 - loss: 0.6430\n",
      "Epoch 88/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5622 - loss: 0.6506 \n",
      "Epoch 89/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.5276 - loss: 0.6730\n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5727 - loss: 0.6730 \n",
      "Epoch 91/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5604 - loss: 0.6861 \n",
      "Epoch 92/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6450 - loss: 0.6496 \n",
      "Epoch 93/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.6149 - loss: 0.6537\n",
      "Epoch 94/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.5058 - loss: 0.6707\n",
      "Epoch 95/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.6329 - loss: 0.6426\n",
      "Epoch 96/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5160 - loss: 0.6943 \n",
      "Epoch 97/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5731 - loss: 0.7098 \n",
      "Epoch 98/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6262 - loss: 0.6435 \n",
      "Epoch 99/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.6243 - loss: 0.6375\n",
      "Epoch 100/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.6266 - loss: 0.6779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c7d81af5c0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7965 - loss: 0.6408  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6414833068847656, 0.7884615659713745]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
